{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49ff27e7",
   "metadata": {},
   "source": [
    "# Regressão Logística para Classificação de Câncer de Mama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4510a86",
   "metadata": {},
   "source": [
    "A seguinte análise objetiva o estudo e desenvolvimento de um algoritmo, desenvolvendo as funções de ativação, de treinamento e previsão utilizando apenas a biblioteca NumPy, enquanto solidificação dos conhecimentos em Regressão Logística, Cálculo e Linguagem de Programação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6749f53a",
   "metadata": {},
   "source": [
    "### Parte 1. Importação de Bibliotecas e Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3032649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split #Utilizado para separar o dataset em treinamento e teste\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt #Utilizado para a visualização dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3774f0cf",
   "metadata": {},
   "source": [
    "### Parte 2. Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c4fa24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bc = datasets.load_breast_cancer() #Acessando o dataset\n",
    "X, y = bc.data, bc.target #Separando o dataset em inputs (X) e outputs (y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cbd7982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "#Acessando o conteúdo do dataset\n",
    "print(bc.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2d11d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "#Acessando o nome dos features que estão sendo usado para classificação\n",
    "print(bc['feature_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7740bc",
   "metadata": {},
   "source": [
    "### Parte 3. Criação de Classes e funções necessárias para cálculo de pesos e bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2eaf6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função de Ativação - Sigmoide\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "class LogisticRegression():\n",
    "    #Inicialização dos parâmetros necessários\n",
    "    def __init__(self, lr=0.001, n_iters=1000):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    #Inicialização do processo de treinamento\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        #Laço de repetição utilizado para treinamento, considerando o número de iterações informado\n",
    "        for _ in range(self.n_iters):\n",
    "            linear_pred = np.dot(X, self.weights) + self.bias\n",
    "            predictions = sigmoid(linear_pred)\n",
    "\n",
    "            dw = (1/n_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1/n_samples) * np.sum(predictions-y)\n",
    "\n",
    "            self.weights = self.weights - self.lr*dw\n",
    "            self.bias = self.bias - self.lr*db\n",
    "    \n",
    "    def predict(self, X):\n",
    "        linear_pred = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = sigmoid(linear_pred)\n",
    "        class_pred = [0 if y<=0.5 else 1 for y in y_pred]\n",
    "        return class_pred\n",
    "\n",
    "#Inicialização de função de precisão\n",
    "def accuracy(y_pred, y_test):\n",
    "    return np.sum(y_pred==y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19af55fe",
   "metadata": {},
   "source": [
    "### Parte 4. Aplicação da Regressão Logística no dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "456bf470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A precisão do modelo obtido é de: 92.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mailon\\AppData\\Local\\Temp\\ipykernel_14096\\4030542122.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "#Aplicação da Regressão Logística\n",
    "clf = LogisticRegression(lr=0.01)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#Cálculo da Precisão do Modelo Obtido\n",
    "acc = accuracy(y_pred, y_test)\n",
    "print(f\"A precisão do modelo obtido é de: {acc.round(4)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b26e8e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>Value_pred</th>\n",
       "      <th>Cancer_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.670</td>\n",
       "      <td>20.02</td>\n",
       "      <td>75.21</td>\n",
       "      <td>416.2</td>\n",
       "      <td>0.10160</td>\n",
       "      <td>0.09453</td>\n",
       "      <td>0.04200</td>\n",
       "      <td>0.02157</td>\n",
       "      <td>0.1859</td>\n",
       "      <td>0.06461</td>\n",
       "      <td>...</td>\n",
       "      <td>87.00</td>\n",
       "      <td>550.6</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>0.27580</td>\n",
       "      <td>0.08120</td>\n",
       "      <td>0.3206</td>\n",
       "      <td>0.08950</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.800</td>\n",
       "      <td>9.71</td>\n",
       "      <td>68.77</td>\n",
       "      <td>357.6</td>\n",
       "      <td>0.09594</td>\n",
       "      <td>0.05736</td>\n",
       "      <td>0.02531</td>\n",
       "      <td>0.01698</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.06400</td>\n",
       "      <td>...</td>\n",
       "      <td>73.66</td>\n",
       "      <td>414.0</td>\n",
       "      <td>0.1436</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.04603</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.07699</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.450</td>\n",
       "      <td>16.41</td>\n",
       "      <td>82.85</td>\n",
       "      <td>476.7</td>\n",
       "      <td>0.09514</td>\n",
       "      <td>0.15110</td>\n",
       "      <td>0.15440</td>\n",
       "      <td>0.04846</td>\n",
       "      <td>0.2082</td>\n",
       "      <td>0.07325</td>\n",
       "      <td>...</td>\n",
       "      <td>97.82</td>\n",
       "      <td>580.6</td>\n",
       "      <td>0.1175</td>\n",
       "      <td>0.4061</td>\n",
       "      <td>0.48960</td>\n",
       "      <td>0.13420</td>\n",
       "      <td>0.3231</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.465</td>\n",
       "      <td>21.01</td>\n",
       "      <td>60.11</td>\n",
       "      <td>269.4</td>\n",
       "      <td>0.10440</td>\n",
       "      <td>0.07773</td>\n",
       "      <td>0.02172</td>\n",
       "      <td>0.01504</td>\n",
       "      <td>0.1717</td>\n",
       "      <td>0.06899</td>\n",
       "      <td>...</td>\n",
       "      <td>67.03</td>\n",
       "      <td>330.7</td>\n",
       "      <td>0.1548</td>\n",
       "      <td>0.1664</td>\n",
       "      <td>0.09412</td>\n",
       "      <td>0.06517</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.09211</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.650</td>\n",
       "      <td>13.16</td>\n",
       "      <td>87.88</td>\n",
       "      <td>568.9</td>\n",
       "      <td>0.09646</td>\n",
       "      <td>0.08711</td>\n",
       "      <td>0.03888</td>\n",
       "      <td>0.02563</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.06344</td>\n",
       "      <td>...</td>\n",
       "      <td>99.71</td>\n",
       "      <td>706.2</td>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.2474</td>\n",
       "      <td>0.17590</td>\n",
       "      <td>0.08056</td>\n",
       "      <td>0.2380</td>\n",
       "      <td>0.08718</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>11.750</td>\n",
       "      <td>20.18</td>\n",
       "      <td>76.10</td>\n",
       "      <td>419.8</td>\n",
       "      <td>0.10890</td>\n",
       "      <td>0.11410</td>\n",
       "      <td>0.06843</td>\n",
       "      <td>0.03738</td>\n",
       "      <td>0.1993</td>\n",
       "      <td>0.06453</td>\n",
       "      <td>...</td>\n",
       "      <td>88.91</td>\n",
       "      <td>543.9</td>\n",
       "      <td>0.1358</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>0.19560</td>\n",
       "      <td>0.07909</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.07987</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>18.610</td>\n",
       "      <td>20.25</td>\n",
       "      <td>122.10</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>0.09440</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.07731</td>\n",
       "      <td>0.1697</td>\n",
       "      <td>0.05699</td>\n",
       "      <td>...</td>\n",
       "      <td>139.90</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>0.34460</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.07421</td>\n",
       "      <td>0</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>13.270</td>\n",
       "      <td>14.76</td>\n",
       "      <td>84.74</td>\n",
       "      <td>551.7</td>\n",
       "      <td>0.07355</td>\n",
       "      <td>0.05055</td>\n",
       "      <td>0.03261</td>\n",
       "      <td>0.02648</td>\n",
       "      <td>0.1386</td>\n",
       "      <td>0.05318</td>\n",
       "      <td>...</td>\n",
       "      <td>104.50</td>\n",
       "      <td>830.6</td>\n",
       "      <td>0.1006</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.13500</td>\n",
       "      <td>0.10010</td>\n",
       "      <td>0.2027</td>\n",
       "      <td>0.06206</td>\n",
       "      <td>0</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>13.430</td>\n",
       "      <td>19.63</td>\n",
       "      <td>85.84</td>\n",
       "      <td>565.4</td>\n",
       "      <td>0.09048</td>\n",
       "      <td>0.06288</td>\n",
       "      <td>0.05858</td>\n",
       "      <td>0.03438</td>\n",
       "      <td>0.1598</td>\n",
       "      <td>0.05671</td>\n",
       "      <td>...</td>\n",
       "      <td>116.60</td>\n",
       "      <td>993.6</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.1546</td>\n",
       "      <td>0.26440</td>\n",
       "      <td>0.11600</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.07371</td>\n",
       "      <td>0</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>27.420</td>\n",
       "      <td>26.27</td>\n",
       "      <td>186.90</td>\n",
       "      <td>2501.0</td>\n",
       "      <td>0.10840</td>\n",
       "      <td>0.19880</td>\n",
       "      <td>0.36350</td>\n",
       "      <td>0.16890</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>251.20</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>0.68330</td>\n",
       "      <td>0.26250</td>\n",
       "      <td>0.2641</td>\n",
       "      <td>0.07427</td>\n",
       "      <td>0</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0         11.670         20.02           75.21      416.2          0.10160   \n",
       "1         10.800          9.71           68.77      357.6          0.09594   \n",
       "2         12.450         16.41           82.85      476.7          0.09514   \n",
       "3          9.465         21.01           60.11      269.4          0.10440   \n",
       "4         13.650         13.16           87.88      568.9          0.09646   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "109       11.750         20.18           76.10      419.8          0.10890   \n",
       "110       18.610         20.25          122.10     1094.0          0.09440   \n",
       "111       13.270         14.76           84.74      551.7          0.07355   \n",
       "112       13.430         19.63           85.84      565.4          0.09048   \n",
       "113       27.420         26.27          186.90     2501.0          0.10840   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.09453         0.04200              0.02157         0.1859   \n",
       "1             0.05736         0.02531              0.01698         0.1381   \n",
       "2             0.15110         0.15440              0.04846         0.2082   \n",
       "3             0.07773         0.02172              0.01504         0.1717   \n",
       "4             0.08711         0.03888              0.02563         0.1360   \n",
       "..                ...             ...                  ...            ...   \n",
       "109           0.11410         0.06843              0.03738         0.1993   \n",
       "110           0.10660         0.14900              0.07731         0.1697   \n",
       "111           0.05055         0.03261              0.02648         0.1386   \n",
       "112           0.06288         0.05858              0.03438         0.1598   \n",
       "113           0.19880         0.36350              0.16890         0.2061   \n",
       "\n",
       "     mean fractal dimension  ...  worst perimeter  worst area  \\\n",
       "0                   0.06461  ...            87.00       550.6   \n",
       "1                   0.06400  ...            73.66       414.0   \n",
       "2                   0.07325  ...            97.82       580.6   \n",
       "3                   0.06899  ...            67.03       330.7   \n",
       "4                   0.06344  ...            99.71       706.2   \n",
       "..                      ...  ...              ...         ...   \n",
       "109                 0.06453  ...            88.91       543.9   \n",
       "110                 0.05699  ...           139.90      1403.0   \n",
       "111                 0.05318  ...           104.50       830.6   \n",
       "112                 0.05671  ...           116.60       993.6   \n",
       "113                 0.05623  ...           251.20      4254.0   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0              0.1550             0.2964          0.27580   \n",
       "1              0.1436             0.1257          0.10470   \n",
       "2              0.1175             0.4061          0.48960   \n",
       "3              0.1548             0.1664          0.09412   \n",
       "4              0.1311             0.2474          0.17590   \n",
       "..                ...                ...              ...   \n",
       "109            0.1358             0.1892          0.19560   \n",
       "110            0.1338             0.2117          0.34460   \n",
       "111            0.1006             0.1238          0.13500   \n",
       "112            0.1401             0.1546          0.26440   \n",
       "113            0.1357             0.4256          0.68330   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  \\\n",
       "0                 0.08120          0.3206                  0.08950   \n",
       "1                 0.04603          0.2090                  0.07699   \n",
       "2                 0.13420          0.3231                  0.10340   \n",
       "3                 0.06517          0.2878                  0.09211   \n",
       "4                 0.08056          0.2380                  0.08718   \n",
       "..                    ...             ...                      ...   \n",
       "109               0.07909          0.3168                  0.07987   \n",
       "110               0.14900          0.2341                  0.07421   \n",
       "111               0.10010          0.2027                  0.06206   \n",
       "112               0.11600          0.2884                  0.07371   \n",
       "113               0.26250          0.2641                  0.07427   \n",
       "\n",
       "     Value_pred  Cancer_Class  \n",
       "0             1        Benign  \n",
       "1             1        Benign  \n",
       "2             1        Benign  \n",
       "3             1        Benign  \n",
       "4             1        Benign  \n",
       "..          ...           ...  \n",
       "109           1        Benign  \n",
       "110           0     Malignant  \n",
       "111           0     Malignant  \n",
       "112           0     Malignant  \n",
       "113           0     Malignant  \n",
       "\n",
       "[114 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_data = pd.DataFrame(X_test, columns = ['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
    " 'mean smoothness', 'mean compactness', 'mean concavity',\n",
    " 'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
    " 'radius error', 'texture error', 'perimeter error' ,'area error',\n",
    " 'smoothness error', 'compactness error', 'concavity error',\n",
    " 'concave points error', 'symmetry error', 'fractal dimension error',\n",
    " 'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
    " 'worst smoothness', 'worst compactness', 'worst concavity',\n",
    " 'worst concave points', 'worst symmetry', 'worst fractal dimension'])\n",
    "pred = pd.DataFrame(y_pred, columns=['Value_pred'])\n",
    "result = pd.concat([features_data, pred], axis=1)\n",
    "\n",
    "pred_class = []\n",
    "for i in result.itertuples():\n",
    "    if i.Value_pred == 1:\n",
    "        pred_class.append(\"Benign\")\n",
    "    else: \n",
    "        pred_class.append(\"Malignant\")\n",
    "result[\"Cancer_Class\"] = pred_class\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
